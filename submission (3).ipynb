{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422df561",
   "metadata": {},
   "source": [
    "## Machine Learning-Driven Property Valuation in NYC Real Estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390b722",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "1. Vishveshwara Guthal (guthal)\n",
    "2. Ariscia Mendes (amende17)\n",
    "3. Swetha Narasimhan (Swetha1999)(POC)\n",
    "4. Amaan Ali Khan (ak0477)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74757b95",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Accurate real estate property valuation is a critical need for stakeholders such as real estate companies, insurance firms, and home buyers. These stakeholders rely on precise pricing to make informed decisions on investments, insurance coverage, and purchases. Traditional valuation methods (e.g., comparative market analysis or expert appraisals) often struggle to adapt to rapid market changes and complex feature interactions.\n",
    "\n",
    "To address this, our project leverages machine learning to estimate property values more reliably. In particular, we develop models using XGBoost (an ensemble gradient boosting method) and deep neural networks to predict property sale prices from a dataset of New York City (NYC) properties. By learning from historical data – including property attributes, location features, and neighborhood characteristics – these models aim to deliver data-driven valuations that meet the high accuracy demands of stakeholders. In summary, we propose a machine learning solution that ingests diverse property data and outputs an estimated market value for each property, providing an automated valuation tool for NYC real estate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab12dde",
   "metadata": {},
   "source": [
    "# Literature Survey\n",
    "Sharma, Harsora, and Ogunleye (2024) evaluated several algorithms including Support Vector Regression, Random Forest, Multilayer Perceptrons (a type of deep neural network), and XGBoost for house price prediction. Their study found that XGBoost performed consistently well across evaluation metrics, primarily due to its ability to handle nonlinear relationships and missing data. DNNs also showed competitive performance but required more tuning and were less interpretable in comparison.\n",
    "\n",
    "Abdul Rahman, Mutalib, and Zulkifley (2021) compared XGBoost and LightGBM against simpler models like linear regression. XGBoost achieved lower prediction errors, supporting its suitability for problems involving complex feature interactions such as those commonly found in real estate datasets.\n",
    "\n",
    "A 2024 ArXiv preprint titled \"An Optimal House Price Prediction Algorithm: XGBoost\" highlighted XGBoost’s capability to deal with varying data quality and to model interactions without the need for extensive feature engineering. This is relevant in practical housing datasets where data can be noisy or incomplete.\n",
    "\n",
    "A study published in JETIR (2024) also applied XGBoost to housing price prediction. The paper emphasized its robustness across different feature sets and market conditions, particularly in datasets with a large number of variables. The model's built-in feature importance ranking was also noted as useful for interpretability.\n",
    "\n",
    "Another recent study from Pioneer Publisher (2024), using Ames housing data, concluded that XGBoost provided more accurate predictions than traditional models. It performed well in capturing variable interactions, which is beneficial in scenarios with diverse property characteristics.\n",
    "\n",
    "In addition to XGBoost, some studies explored the use of deep neural networks. While DNNs generally require more data and tuning, they can be effective in capturing complex nonlinear relationships, especially when working with high-dimensional structured data. A few research papers suggest using DNNs when the dataset includes a wide range of features or non-tabular inputs, although interpretability remains a limitation.\n",
    "\n",
    "Overall, the literature supports the use of XGBoost for structured, tabular housing datasets due to its accuracy and handling of feature interactions. DNNs, while less interpretable, are considered a strong alternative when modeling more complex patterns or integrating additional data types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9bdef",
   "metadata": {},
   "source": [
    "# Data and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a3d06",
   "metadata": {},
   "source": [
    "**Data**\n",
    "\n",
    "The dataset used in this study contains 10,465 rows and 40 columns, compiled from publicly available real estate sources such as Zillow and Realtor.com, along with neighborhood level information. It includes core property features like property type, area in square feet, number of beds and baths, borough, lot size, and property value. What makes this dataset particularly useful for modeling is its integration of contextual variables that influence housing decisions but are often missing from traditional datasets. It includes actual crime data from NYPD and Data.gov and calculated distances to nearby amenities using OpenStreetMap, providing a fuller picture of both property characteristics and neighborhood conditions.\n",
    "\n",
    "Location based features were further enriched by calculating distances to nearby amenities including parks, schools, malls, and public transport using geocoding data from the OpenStreetMap API. This allows the dataset to reflect not only the physical attributes of a property but also its surrounding environment, which can play a significant role in housing preferences and pricing.\n",
    "\n",
    "The dataset includes a balanced mix of numerical and categorical features. Numerical data covers metrics such as safety score, area, latitude, longitude, and proximity counts to local services. Categorical variables include attributes like borough, type of house, bed and bath count, and grouped distance ranges. This structure supports both classification and regression tasks, depending on the modeling objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeae89b",
   "metadata": {},
   "source": [
    "**Visualization**\n",
    "\n",
    "\n",
    "The below bar chart shows that properties within 0–1 mile of a metro station have the highest average prices. This suggests that proximity to public transportation significantly boosts property value. It emphasizes the role of accessibility in real estate pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea6149",
   "metadata": {},
   "source": [
    "![](EDA1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99448e63",
   "metadata": {},
   "source": [
    "The below graph highlights that safety scores vary notably across boroughs, with Staten Island being the highest. Since safety is a major factor in homebuyer decisions, it can influence property demand. This justifies including safety as a predictive feature for house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2ca12",
   "metadata": {},
   "source": [
    "![](EDA2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ca10d",
   "metadata": {},
   "source": [
    "**Methods**\n",
    "\n",
    "We approached the problem as a supervised regression task: using property features and neighborhood-level data to predict housing prices. The two primary models we used were XGBoost and a deep neural network, implemented using Python libraries including scikit-learn, XGBoost, and TensorFlow/Keras.\n",
    "\n",
    "The cleaned dataset was split into training and test sets, with stratification by borough to maintain geographic representation. Categorical features were one-hot encoded using a column transformer, and numerical features were standardized for the neural network. We also applied a log transformation to the target variable for the neural network to improve learning stability, while XGBoost was trained on both the original and log-transformed values as part of our experiments.\n",
    "\n",
    "For XGBoost, we tuned hyperparameters like tree depth, number of estimators, and learning rate using cross-validation and early stopping. The model performed well with minimal preprocessing and gave useful feature importance scores. For the deep neural network, we used a feedforward structure with two hidden layers, ReLU activation, dropout for regularization, and early stopping to avoid overfitting. The model was trained with the Adam optimizer and evaluated using validation performance.\n",
    "\n",
    "We evaluated both models using root mean squared error (RMSE), mean absolute error (MAE), and R-squared. These metrics provide an understanding of prediction accuracy in dollar terms and explain the proportion of variance captured by the model. Using both models allowed us to compare approaches and better understand which features contributed to price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855cfd2",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc09819",
   "metadata": {},
   "source": [
    "We evaluated both models: XGBoost and Deep Neural Network (DNN), using 5-fold cross-validation on the training set to tune hyperparameters and assess consistency. After tuning, we selected the best configurations and tested both models on a held-out test set to estimate real-world performance. Evaluation metrics include Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) in dollars, as well as R² (R-squared) to measure variance explained. These metrics reflect stakeholder priorities by indicating both average error and overall model reliability in dollars.\n",
    "\n",
    "Performance results are summarized in the table below:\n",
    "\n",
    "| Model   | R² (R-squared) | RMSE         |\n",
    "|---------|----------------|--------------|\n",
    "| XGBoost | 90.5           | $549,905.47  |\n",
    "| DNN     | 85.32          | $430,831.33  |\n",
    "\n",
    "Lower RMSE and MAE indicate better performance. R² closer to 1 indicates stronger explanatory power.\n",
    "\n",
    "The XGBoost model achieved the best performance, with an R² of 90.5 and an RMSE of approximately $549,905.47, indicating strong predictive capability. The Deep Neural Network (DNN) model followed closely with an R² of 84.29 and a lower RMSE of $430,831.33, suggesting it made smaller average errors despite a slightly lower R². Both models significantly outperformed baseline approaches such as linear regression or constant mean prediction.\n",
    "\n",
    "To understand the models further, we extracted feature importances from the trained XGBoost model. The top predictive features included gross square footage, borough (particularly Manhattan), safety score, number of nearby transit stops, and school density. These results align with expectations: properties in safer areas with better accessibility and education infrastructure tend to be priced higher. A visualization of feature importances is included below:\n",
    "\n",
    "![](FImp.png)\n",
    "\n",
    "We also evaluated model accuracy by borough to identify geographic disparities. Both models performed best in Manhattan and Queens, where data was more abundant and structured. Performance was slightly less consistent in Staten Island, likely due to limited data and its distinct housing market. Still, R² values remained above 0.75 across all boroughs.\n",
    "\n",
    "Although our focus was regression, we briefly assessed the model’s output in a binary classification setting: predicting whether a property is above or below median price. Using XGBoost predictions with a threshold at the median, we observed a classification accuracy of around 90 percent and an F1 score of 0.88 for high-value properties. These results demonstrate that the model’s price predictions are also meaningful in categorical terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b6ce0c",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44895b66",
   "metadata": {},
   "source": [
    "\n",
    "Our goal was to build a predictive model that estimates residential property values using both physical features and location-based attributes. Based on the results, we believe we achieved this goal. The XGBoost model, in particular, demonstrated high accuracy with RMSE and MAE values within the typical range of real estate transactions. This level of precision meets the practical expectations of most stakeholders, including real estate professionals, investors, insurers, and prospective buyers.\n",
    "\n",
    "For real estate companies and investors, the model can flag potentially undervalued listings, supporting faster, data-driven decision-making. For example, if the model predicts a value significantly higher than a listing price, it may identify an investment opportunity. Insurance companies can benefit from consistent, scalable property valuations for underwriting purposes, particularly since the model includes risk-related features like neighborhood safety. For home buyers, the tool provides transparent insights into how different property factors influence value, improving buyer confidence and understanding.\n",
    "\n",
    "Beyond accuracy, the model also surfaced meaningful insights. For instance, safety scores and proximity to transit or schools were key value drivers, and the diminishing returns on property size provided a nuanced understanding of market behavior. These insights align with known market dynamics and validate that the model captures real-world patterns. While the models performed well, there is still room for improvement.\n",
    "\n",
    "In terms of stakeholder needs, we addressed the core requirement: delivering fast, reasonably accurate, and interpretable property valuations. However, deployment as a real-world tool would require additional features such as an interactive interface, continuous model retraining with new data, and clear disclaimers about prediction uncertainty.\n",
    "\n",
    "In summary, our work successfully demonstrates that machine learning can support property valuation in a scalable and insightful way. While not a replacement for expert appraisal, the model effectively narrows the margin of error and serves as a valuable decision-support tool across multiple use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ddba46",
   "metadata": {},
   "source": [
    "# Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413343c",
   "metadata": {},
   "source": [
    "While our models delivered reasonable predictive performance, there are several limitations that affect the generalizability, robustness, and fairness of our results.\n",
    "\n",
    "**Data coverage and missing attributes:**\n",
    "\n",
    "The model is trained on available public records and scraped housing features, which do not capture all influential property characteristics. Details such as interior condition, recent renovations, or specific views were not included due to data limitations. As a result, the model may misprice properties with unique unrecorded features. The dataset also skews toward standard residential units (1–2 family homes, condos), limiting its applicability to commercial or multi-unit buildings.\n",
    "\n",
    "**Time sensitivity and market dynamics:**\n",
    "\n",
    "The model assumes a relatively static mapping between features and price. However, real estate markets are affected by time-dependent factors like interest rate changes, new policies, or post-pandemic shifts. Since our data spans multiple years but does not include recent fluctuations beyond 2022, there is a risk that predictions may be outdated. Retraining the model periodically with updated sales records would be necessary for reliable deployment.\n",
    "\n",
    "**Limitations Across Different Cities**\n",
    "\n",
    "Our training data is specific to New York City, and model insights (e.g., importance of subway proximity) reflect that context. These relationships may not hold in other cities or rural areas. Even within NYC, the model cannot account for future development or neighborhood gentrification not present in the training data. Extending this model to other locations would require retraining with region-specific data.\n",
    "\n",
    "**Bias and fairness concerns:**\n",
    "\n",
    "Because the model learns from historical sale prices, it can reflect and reinforce existing socioeconomic biases in property valuation. For example, areas with historically lower investment may continue to be undervalued by the model. We did not implement fairness constraints or debiasing techniques, which would be important for any use in lending or insurance contexts. This limits the model’s social fairness despite its technical accuracy.\n",
    "\n",
    "**Neural network limitations:**\n",
    "\n",
    "While the DNN model functioned reasonably well, it did not outperform XGBoost. This may be due to limited data, architectural simplicity, or the absence of richer inputs like textual property descriptions or images. More advanced deep learning approaches or hybrid models could improve performance but were outside the scope of this project.\n",
    "\n",
    "**External features and spatial granularity:**\n",
    "\n",
    "We included basic amenity counts and a safety score derived from precinct-level clustering. While these features added value, they were coarse approximations. For example, a high crime precinct might contain very safe sub-neighborhoods, which our model could not distinguish. More detailed crime and amenity data at the block level would improve spatial accuracy.\n",
    "\n",
    "In summary, the models provide useful predictions for typical properties in NYC using available features, but they are not substitutes for professional appraisals in edge cases. To make the work more robust, we would need access to richer property data, implement fairness constraints, and adapt the model to handle changing market conditions. These improvements would help meet a wider range of stakeholder needs with greater confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125ea61",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89695ce2",
   "metadata": {},
   "source": [
    "There are several avenues to improve and extend this project:\n",
    "\n",
    "**1. Incorporate Additional Data Sources**\n",
    "Future iterations could integrate more feature types, such as property images (using computer vision to assess condition or curb appeal), detailed text descriptions from listings (processed with NLP to extract features like “has fireplace” or “needs renovation”), and market indicators (interest rates, economic indices at the time of sale). These could enhance the model’s understanding. For example, images combined with a DNN could let the model factor in visual home quality, and text could provide info on indoor amenities. This multi-modal approach might reduce the error further.\n",
    "\n",
    "**2. Geospatial Modeling**\n",
    "The current model handles location via engineered features (borough, coordinates, etc.), but more explicit spatial modeling could help. One idea is to use a graph-based deep learning model or a geospatial kernel that considers relationships between nearby properties. A graph neural network could treat properties as nodes connected by distance or neighborhood similarity, learning value propagation in space. This might capture local market effects better than just using latitude/longitude in a linear way. Alternatively, clustering similar neighborhoods and giving cluster IDs as features might improve predictions for areas with sparse data.\n",
    "\n",
    "**3. Ensemble and Stacking Models**\n",
    "We could combine the strengths of XGBoost and DNN through an ensemble. For instance, using a weighted average or a meta-learner that takes both predictions could yield a small boost in accuracy. In many Kaggle competitions, ensemble of top models often yields the best performance. We could also explore other algorithms like LightGBM or CatBoost (boosting algorithms like XGBoost) to see if they offer improvements in speed or accuracy. Hyperparameter tuning with more computational resources (e.g., Bayesian optimization) could also find better models.\n",
    "\n",
    "**4. Time-Aware Modeling**\n",
    "To handle market trends, a future model could explicitly incorporate time. A rolling training approach could be used, or even a hybrid model that includes a time-series component (e.g., using an ARIMA or LSTM on overall price index combined with the property-level model). This way, as the market goes up or down, the model adjusts the baseline values accordingly. Another idea is to retrain or fine-tune the model periodically (monthly or quarterly) as new sales data comes in, which would keep the model up-to-date.\n",
    "\n",
    "**5. User Interface and Deployment**\n",
    "Building on our Streamlit app for amenities, we envision a full web application for property valuation. A user could enter an address (the system geocodes it), and the model returns an estimated price along with a breakdown of contributing factors (“prediction explanation”). Future work can focus on optimizing this pipeline and possibly allowing feedback. For example, homeowners could input recent renovations or condition (which the model might not know) to adjust the estimate. Gathering such feedback can create a loop to improve the model over time.\n",
    "\n",
    "**6. Handling Limitations**\n",
    "We should address biases by calibrating the model with domain knowledge. Future work could incorporate fairness adjustments to avoid undervaluing properties in historically underpriced areas if the goal is equitable valuation. More granular safety data or amenity importance through surveys could refine these features. Another improvement could involve training separate sub-models for different boroughs or property types (since market dynamics differ), then combining them—e.g., one model specialized for Manhattan condos, another for suburban Staten Island houses.\n",
    "\n",
    "**7. Improving the DNN**\n",
    "If pursuing deep learning further, experimenting with architecture (more layers, different activation functions, or even trying autoencoders for feature reduction) could yield gains. Using a larger dataset (e.g., expanding to all NYC sales from the past 15+ years) would particularly help the DNN, as neural networks typically shine with big data. We could also try a residual network style or incorporate feature interactions via embedding layers.\n",
    "\n",
    "In conclusion, this project lays a strong foundation for ML-based property valuation. The next steps involve enhancing data richness, model sophistication, and deployment capability. By iteratively improving on these fronts, we aim to develop a robust, generalizable, and user-friendly property valuation system. This would not only serve the immediate stakeholders in NYC but could be adapted to other regions, advancing the state of automated real estate appraisal in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
